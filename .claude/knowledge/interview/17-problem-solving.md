# 문제 해결 사례

## 답변 프레임워크: STAR

모든 Behavioral 질문에 STAR 기법을 적용한다.

- **S**ituation: 상황/배경
- **T**ask: 해결해야 할 과제
- **A**ction: 내가 취한 행동
- **R**esult: 결과 및 배운 점

---

## 사례 1: 데이터 정합성 98% → 100% 개선

### 예상 질문
"어려운 기술적 문제를 해결한 경험이 있나요?"

### Situation
한화솔루션 HEMS 프로젝트에서 50만대 장비의 Telemetry 데이터를 수집하고 있었다. 데이터 수집 성공률이 98%로, 2%의 데이터가 유실되고 있었다.

### Task
- 유실되는 2%의 원인 파악
- 데이터 정합성 100% 달성
- 재발 방지 체계 구축

### Action
1. **문제 분석**
   - Kafka Consumer 로그 분석
   - 실패 케이스 패턴 파악
   - 특정 펌웨어 버전에서 비정상 데이터 발견

2. **DLT(Dead Letter Topic) 도입**
   - 처리 실패 메시지를 DLT로 전송
   - 원인별 분류 (파싱 오류, 유효성 오류, 일시적 오류)

3. **재처리 메커니즘 구현**
   - 일시적 오류: 자동 재시도 (Exponential Backoff)
   - 영구적 오류: 알림 + 수동 처리

4. **모니터링 강화**
   - DLT 메시지 수 대시보드
   - 오류 유형별 알림

### Result
- 데이터 정합성 **98% → 100%** 달성
- 기존에 발견하지 못한 **수십 개 엣지 케이스** 발견 및 해결
- 팀 내 DLT 패턴 표준화

### 배운 점
- "완벽"보다 "관찰 가능"이 먼저다
- 실패를 숨기지 말고 가시화해야 한다
- 자동화된 재처리가 운영 부담을 줄인다

---

## 사례 2: 분당 50만 건 데이터 처리 아키텍처

### 예상 질문
"대용량 데이터 처리 경험이 있나요?"

### Situation
한화솔루션에서 장비 수가 기존 수만 대에서 50만대로 확장되었다. 기존 아키텍처로는 분당 50만 건 데이터를 처리할 수 없었다.

### Task
- 분당 50만 건 데이터 안정적 처리
- 기존 서비스 중단 없이 마이그레이션
- 확장 가능한 아키텍처 설계

### Action
1. **병목 지점 분석**
   - 단건 INSERT가 가장 큰 병목
   - Consumer 처리 속도 < Producer 발행 속도

2. **Batch Consumer 도입**
   - `max.poll.records` 튜닝 (500건)
   - 배치 단위 처리로 오버헤드 감소

3. **Bulk Insert 구현**
   - Spring JDBC `batchUpdate`
   - `reWriteBatchedInserts=true` 설정

4. **부하 테스트**
   - Kafka 부하 시뮬레이터 개발
   - 점진적 트래픽 증가 테스트

### Result
- **분당 50만 건** 안정적 처리
- INSERT 성능 **10배 이상** 향상
- 무중단 마이그레이션 성공

### 배운 점
- 성능 문제는 측정 먼저, 추측하지 말 것
- 배치 처리가 단건 처리보다 항상 효율적
- 부하 테스트는 프로덕션 전에 필수

---

## 사례 3: OpenFGA ListObjects 1,000건 제한 해결

### 예상 질문
"기술적 제약을 극복한 경험이 있나요?"

### Situation
42dot에서 OpenFGA를 도입했는데, ListObjects API가 최대 1,000건만 반환하고 페이지네이션을 지원하지 않았다. 차량 수가 수만 대인 상황에서 문제가 되었다.

### Task
- 1,000건 이상의 권한 목록 조회 지원
- 기존 UX 유지
- 성능 저하 최소화

### Action
1. **문제 정의**
   - OpenFGA 공식 문서 및 GitHub Issue 분석
   - 알려진 한계, 해결 가능 여부 확인

2. **대안 설계**
   - **Pragmatic Filtering**: 테넌트 ID로 먼저 필터링
   - **그룹 기반 UX**: 사용자는 그룹에 속하고, 그룹에 리소스 권한 부여
   - **Dual Source**: 권한 확인은 OpenFGA, 목록 조회는 도메인 DB

3. **구현**
   ```kotlin
   // 1. 도메인 DB에서 후보 조회 (테넌트 필터링)
   val candidates = vehicleRepository.findByTenantId(tenantId)

   // 2. OpenFGA BatchCheck로 권한 필터링
   val authorized = fgaClient.batchCheck(candidates)
   ```

4. **문서화**
   - 패턴 문서화 및 팀 공유
   - 블로그 포스팅

### Result
- 1,000건 제한 **우회 성공**
- 응답 시간 **적정 수준 유지**
- 팀 내 ReBAC 이해도 향상

### 배운 점
- 라이브러리/프레임워크 한계를 이해하고 우회하는 것도 능력
- 문제를 재정의하면 해결책이 보인다
- 문서화는 미래의 나와 팀을 위한 투자

---

## 사례 4: 테스트 커버리지 0% → 90%

### 예상 질문
"품질 개선을 위해 노력한 경험이 있나요?"

### Situation
42dot 신규 프로젝트에서 테스트가 거의 없었다. 배포할 때마다 수동 테스트에 의존했고, 버그가 자주 발생했다.

### Task
- 테스트 커버리지 90% 달성
- 프로덕션과 동일한 테스트 환경 구축
- 팀 내 테스트 문화 정착

### Action
1. **Source Set 분리**
   - `src/test`: 단위 테스트 (빠름)
   - `src/integrationTest`: 통합 테스트 (Testcontainers)

2. **Testcontainers 도입**
   - PostgreSQL, Redis, Kafka 컨테이너
   - H2 대신 실제 DB 사용

3. **Mock 어댑터 패턴**
   - 내부 인프라: 실제 사용
   - 외부 API: Mock 어댑터

4. **베이스 클래스 정립**
   - Context 재사용
   - 테스트 간 데이터 격리

### Result
- 커버리지 **0% → 90%** 달성
- "테스트 통과 → 프로덕션 실패" 사례 **제거**
- 배포 자신감 향상

### 배운 점
- 테스트는 처음부터 작성하는 게 쉽다
- 프로덕션과 동일한 환경이 핵심
- Context 재사용이 테스트 속도의 핵심

---

## 공통 질문

### Q: 가장 어려웠던 버그는?

**답변 구조:**
1. 어떤 버그였는지 (증상)
2. 어떻게 원인을 찾았는지 (디버깅 과정)
3. 어떻게 해결했는지
4. 재발 방지책

**예시 (DLT 사례 활용):**
"특정 펌웨어 버전에서만 발생하는 파싱 오류였습니다. 로그만으로는 원인을 찾기 어려웠고, DLT를 도입해 실패 메시지를 분석하면서 원인을 파악했습니다. 해당 펌웨어의 비정상 데이터 포맷을 처리하도록 수정하고, 이후 유사 케이스를 자동으로 탐지하는 모니터링을 추가했습니다."

### Q: 기술적 결정에서 실수한 경험은?

**답변 구조:**
1. 어떤 결정이었는지
2. 왜 실수였는지
3. 어떻게 바로잡았는지
4. 무엇을 배웠는지

**예시:**
"초기에 H2 인메모리 DB로 테스트를 작성했는데, PostgreSQL과 SQL 문법 차이로 테스트는 통과하지만 프로덕션에서 실패하는 경우가 있었습니다. Testcontainers로 전환하면서 해결했고, '프로덕션과 동일한 환경'이 왜 중요한지 깨달았습니다."

---

## 답변 팁

1. **숫자를 사용하라**
   - "개선했습니다" → "98%에서 100%로 개선했습니다"
   - "빨라졌습니다" → "10배 빨라졌습니다"

2. **내 역할을 명확히 하라**
   - "팀에서 했습니다" → "제가 DLT 아키텍처를 설계하고 구현했습니다"

3. **배운 점을 포함하라**
   - 결과만 말하지 말고 인사이트를 공유

4. **2분 이내로 요약하라**
   - 너무 길면 집중력 저하
   - 면접관이 더 물어보게 하라

---

*다음: [18-collaboration.md](./18-collaboration.md)*
